commit 92152dbb21cab624a5429f8ac948441b38abc501
Author: Michal Kubecek <mkubecek@suse.cz>
Date:   Sun Sep 10 20:30:21 2017 +0200

    vmmon: fix page accounting
    
    global_page_state() was renamed to global_zone_page_state() by commit
    c41f012ade0b ("mm: rename global_page_state to global_zone_page_state").
    However, some more changes are needed (and were in fact needed even with
    kernels older than 4.14.
    
    Since commit 385386cff4c6 ("mm: vmstat: move slab statistics from zone to
    node counters") in v4.13-rc1, NR_SLAB_UNRECLAIMABLE needs to be used with
    global_node_page_state(), in-tree callers were fixed by commit d507e2ebd2c7
    ("mm: fix global NR_SLAB_.*CLAIMABLE counter reads").
    
    Since commit 599d0c954f91 ("mm, vmscan: move LRU lists to node") in
    v4.8-rc1, NR_UNEVICTABLE needs global_node_page_state() rather than
    global_page_state().
    
    Since commit 50658e2e04c1 ("mm: move page mapped accounting to the node")
    in v4.8-rc1, NR_ANON_PAGES needs global_node_page_state() as well. This was
    shortly before it was renamed to NR_ANON_MAPPED but as both got into
    mainline in v4.8-rc1, we can do with one #ifdef.
    
    To keep HostIF_EstimateLockedPageLimit() readable, extract the version
    dependent calls into inline helpers.

diff --git a/vmmon-only/linux/hostif.c b/vmmon-only/linux/hostif.c
index 80b5787..c0d1d60 100644
--- a/vmmon-only/linux/hostif.c
+++ b/vmmon-only/linux/hostif.c
@@ -99,6 +99,37 @@
 #include "vmmonInt.h"
 #include "versioned_atomic.h"
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+#   define global_zone_page_state global_page_state
+#endif
+
+static unsigned long get_nr_slab_unreclaimable(void)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 13, 0)
+   return global_node_page_state(NR_SLAB_UNRECLAIMABLE);
+#else
+   return global_page_state(NR_SLAB_UNRECLAIMABLE);
+#endif
+}
+
+static unsigned long get_nr_unevictable(void)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
+   return global_node_page_state(NR_UNEVICTABLE);
+#else
+   return global_page_state(NR_UNEVICTABLE);
+#endif
+}
+
+static unsigned long get_nr_anon_mapped(void)
+{
+ #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
+   return global_node_page_state(NR_ANON_MAPPED);
+ #else
+   return global_page_state(NR_ANON_PAGES);
+ #endif
+}
+
 /*
  * Determine if we can use high resolution timers.
  */
@@ -1594,16 +1625,11 @@ HostIF_EstimateLockedPageLimit(const VMDriver* vm,                // IN
    unsigned int reservedPages = MEMDEFAULTS_MIN_HOST_PAGES;
    unsigned int hugePages = (vm == NULL) ? 0 :
       BYTES_2_PAGES(vm->memInfo.hugePageBytes);
-   unsigned int lockedPages = global_page_state(NR_PAGETABLE) +
-                              global_page_state(NR_SLAB_UNRECLAIMABLE) +
-                              global_page_state(NR_UNEVICTABLE) +
+   unsigned int lockedPages = global_zone_page_state(NR_PAGETABLE) +
+                              get_nr_slab_unreclaimable() +
+                              get_nr_unevictable() +
                               hugePages + reservedPages;
-   unsigned int anonPages =
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
-      global_page_state(NR_ANON_MAPPED);
-#else
-      global_page_state(NR_ANON_PAGES);
-#endif
+   unsigned int anonPages = get_nr_anon_mapped();
    unsigned int swapPages = BYTES_2_PAGES(linuxState.swapSize);
 
    if (anonPages > swapPages) {
